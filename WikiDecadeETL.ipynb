{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "mathematical-cooling",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from typing import List, Dict, Tuple\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "\n",
    "import wikipediaapi as wk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "affiliated-nigeria",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AbstractETL(ABC):\n",
    "    \n",
    "    @abstractmethod\n",
    "    def extract():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def transform():\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def load():\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "computational-township",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WikiDecadeETL(AbstractETL):\n",
    "    \"\"\"\n",
    "    Getting data specifically from WikiPedia.\n",
    "    In this case wiki pages on historical events data by decade\n",
    "    \"\"\"\n",
    "    ignore_sections = {'Pronunciation varieties','Name for the decade','Further reading','References','External links', \"Notes\"}\n",
    "    \n",
    "    root_query = \"List of decades, centuries, and millennia\"\n",
    "    \n",
    "    def __init__(self, query:str=root_query)->None:\n",
    "        self.query = query\n",
    "        self._service = wk.Wikipedia(\"en\", extract_format=wk.ExtractFormat.WIKI)\n",
    "        self.page = self._service.page(query)\n",
    "        self.core_sections = {};\n",
    "        self.coreSect_sub = {}\n",
    "        self.core_df = None\n",
    "        \n",
    "    def get_drange_links(self, start:int, stop:int) -> dict:\n",
    "        \n",
    "        \"\"\"\n",
    "        # TODO\n",
    "        \n",
    "        This function filters the decade range of interest and is specific to \n",
    "        the root_query\n",
    "        \"\"\"\n",
    "        \n",
    "        drange = [f\"{str(i)}s\" if str(i)[-2:] != \"00\" else f\"{str(i)}s (decade)\" for i in range(start, stop+1, 10)]\n",
    "        \n",
    "        drange_links = dict(zip(drange, map(self.page.links.get, drange)))\n",
    "        \n",
    "        return drange_links\n",
    "        \n",
    "    \n",
    "    def get_page_sections(self)->Tuple[list, dict]:\n",
    "        \"\"\"\n",
    "        Returns dict of wiki page sections, subsections and text\n",
    "        \"\"\"\n",
    "        main_sections = self.page.sections # We have to get the section before getting the section mapping\n",
    "        all_sections_dict = self.page._section_mapping # section mapping is empty if above is not executed first\n",
    "\n",
    "        return main_sections, all_sections_dict\n",
    "\n",
    "    \n",
    "    def core_section_extractor(self)->None:\n",
    "        \n",
    "        \"\"\"\n",
    "        Params: decade\n",
    "        Returns dict of sections_title of key interest that will later be used to extract a sections content\n",
    "            main_section_title : list of subsections\n",
    "        \"\"\"\n",
    "        \n",
    "        main_sections, all_sections_dict = self.get_page_sections()\n",
    "        \n",
    "        # All sections. Main, Subsections and Sections to ignore\n",
    "        all_section_titles = list(all_sections_dict.keys())\n",
    "\n",
    "        # Only the core sections including \"See also\"\n",
    "        core_section_titles = [s.title for s in main_sections if s.title not in self.ignore_sections]\n",
    "        \n",
    "\n",
    "        # Storing the core section indices according to their position in the all_section_title list\n",
    "        core_indices = {k: all_section_titles.index(k) for k in  core_section_titles}\n",
    "\n",
    "        # Convinience variable \n",
    "        indices_lst = list(core_indices.keys())\n",
    "\n",
    "\n",
    "        # Store the core title with a list of its subsections\n",
    "        # core_indices = {\"People\": 14, \"See Also\": 16} - # People is on index 14 on all_section_index with possible 2 subsections\n",
    "        # index_lst = [\"People\", \"See Also\"] - People is at index 0 of core_indices.keys()\n",
    "        # core_dict = {\"People\":[\"World Leaders\", \"Business Leaders\"]}\n",
    "        self.coreSect_sub = {indices_lst[i]:all_section_titles[core_indices[indices_lst[i]]+1: core_indices[indices_lst[i+1]]] \n",
    "                                   for i in range(len(indices_lst)-1)}\n",
    "        \n",
    "        sect_titles = self.coreSect_sub.keys()\n",
    "        # Subseting the all_sections_dict to only the core_sections with subs embeded\n",
    "        self.core_sections = dict(zip(sect_titles, map(all_sections_dict.get, sect_titles)))\n",
    "        \n",
    "        \n",
    "    def get_subtitle(self, val):\n",
    "        \n",
    "        \"\"\"\n",
    "        Returns the subsections title list for a section in an entry.\n",
    "        \n",
    "        If subsections do not exist return the section title\n",
    "        \"\"\"\n",
    "        \n",
    "        res = val\n",
    "        if self.coreSect_sub[val]:\n",
    "            res = self.coreSect_sub[val]\n",
    "        return res\n",
    "    \n",
    "    def get_subtext(self, val):\n",
    "        \"\"\"\n",
    "        Returns the a subsections full texts for an entry\n",
    "        \"\"\"\n",
    "        return self.page.section_by_title(val).full_text()\n",
    "    \n",
    "    def get_df(self):\n",
    "        \n",
    "        \"\"\"\n",
    "        Creating a dataframe from extracted data\n",
    "        \"\"\"\n",
    "        \n",
    "        core_sections = self.core_sections\n",
    "        \n",
    "        temp_df = pd.DataFrame.from_dict(core_sections, orient=\"index\", \n",
    "                                         columns=[\"text\"]).reset_index().rename(columns={\"index\": \"section\"})\n",
    "        \n",
    "        temp_df[\"sub_section\"] = temp_df[\"section\"].apply(self.get_subtitle)\n",
    "        \n",
    "        temp_df = temp_df.explode(\"sub_section\", ignore_index=True)\n",
    "        \n",
    "        temp_df[\"text\"] = temp_df[\"sub_section\"].apply(self.get_subtext)\n",
    "        \n",
    "        temp_df[\"decade\"] = self.query\n",
    "        \n",
    "        self.core_df = temp_df\n",
    "        \n",
    "    def extract(self):\n",
    "        # Mainly for fetching the data we want from Wikipedia\n",
    "        self.core_section_extractor()\n",
    "    \n",
    "    def transform(self):\n",
    "        # Processing the raw data retaining only the parts we want\n",
    "        self.extract()\n",
    "        \n",
    "        self.get_df()\n",
    "    \n",
    "    def load(self):\n",
    "        # Loading the semi-processed data in data frame format.\n",
    "        self.transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "included-niger",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "hindu-blink",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(query:str)->WikiDecadeETL:\n",
    "    \n",
    "    decade = WikiDecadeETL(query)\n",
    "    decade.load()\n",
    "    return decade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "decreased-aerospace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_combined_df(start:int=1900, stop:int=2020)->dict:\n",
    "    \n",
    "    lofdcm = WikiDecadeETL()\n",
    "    drange_links = lofdcm.get_drange_links(start, stop)\n",
    "    \n",
    "    combined_dict = {query: run(query).core_df for query in drange_links.keys()}\n",
    "    \n",
    "    combined_df = pd.concat(combined_dict.values(), ignore_index=True)\n",
    "    \n",
    "    return combined_df\n",
    "        \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "powered-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = get_combined_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cloudy-aurora",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>section</th>\n",
       "      <th>text</th>\n",
       "      <th>sub_section</th>\n",
       "      <th>decade</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Name for the decade</td>\n",
       "      <td>Name for the decade\\nIn the English-speaking w...</td>\n",
       "      <td>Name for the decade</td>\n",
       "      <td>2000s (decade)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Politics and wars</td>\n",
       "      <td>Terrorist attacks\\nThe most prominent terroris...</td>\n",
       "      <td>Terrorist attacks</td>\n",
       "      <td>2000s (decade)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Politics and wars</td>\n",
       "      <td>Wars\\nThe most prominent armed conflicts of th...</td>\n",
       "      <td>Wars</td>\n",
       "      <td>2000s (decade)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Politics and wars</td>\n",
       "      <td>International wars\\nWar on Terror (2001–presen...</td>\n",
       "      <td>International wars</td>\n",
       "      <td>2000s (decade)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Politics and wars</td>\n",
       "      <td>Civil wars and guerrilla wars\\nWar in Darfur (...</td>\n",
       "      <td>Civil wars and guerrilla wars</td>\n",
       "      <td>2000s (decade)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Culture</td>\n",
       "      <td>Music\\nIn 2020, TikTok became an important mus...</td>\n",
       "      <td>Music</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Culture</td>\n",
       "      <td>Video games\\nThe ninth generation of consoles ...</td>\n",
       "      <td>Video games</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Culture</td>\n",
       "      <td>Architecture\\n</td>\n",
       "      <td>Architecture</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Culture</td>\n",
       "      <td>Sports\\nTokyo was to host the Olympic Games fo...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>See also</td>\n",
       "      <td>See also\\nTimeline of the near future\\n\\n</td>\n",
       "      <td>See also</td>\n",
       "      <td>2020s</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 section                                               text  \\\n",
       "0    Name for the decade  Name for the decade\\nIn the English-speaking w...   \n",
       "1      Politics and wars  Terrorist attacks\\nThe most prominent terroris...   \n",
       "2      Politics and wars  Wars\\nThe most prominent armed conflicts of th...   \n",
       "3      Politics and wars  International wars\\nWar on Terror (2001–presen...   \n",
       "4      Politics and wars  Civil wars and guerrilla wars\\nWar in Darfur (...   \n",
       "..                   ...                                                ...   \n",
       "162              Culture  Music\\nIn 2020, TikTok became an important mus...   \n",
       "163              Culture  Video games\\nThe ninth generation of consoles ...   \n",
       "164              Culture                                     Architecture\\n   \n",
       "165              Culture  Sports\\nTokyo was to host the Olympic Games fo...   \n",
       "166             See also          See also\\nTimeline of the near future\\n\\n   \n",
       "\n",
       "                       sub_section          decade  \n",
       "0              Name for the decade  2000s (decade)  \n",
       "1                Terrorist attacks  2000s (decade)  \n",
       "2                             Wars  2000s (decade)  \n",
       "3               International wars  2000s (decade)  \n",
       "4    Civil wars and guerrilla wars  2000s (decade)  \n",
       "..                             ...             ...  \n",
       "162                          Music           2020s  \n",
       "163                    Video games           2020s  \n",
       "164                   Architecture           2020s  \n",
       "165                         Sports           2020s  \n",
       "166                       See also           2020s  \n",
       "\n",
       "[167 rows x 4 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "northern-military",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(start:int=1900, stop:int=2020, version=1):\n",
    "\n",
    "    combined_df = get_combined_df(start, stop)\n",
    "\n",
    "    combined_df.to_csv(f\"data/v{version}_{start}_{stop}s.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "affiliated-peoples",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df.to_csv(\"data/1900_2020s.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "sunset-albania",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "successful-advancement",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bored-princess",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "understood-discrimination",
   "metadata": {},
   "source": [
    "### Todo\n",
    "\n",
    "- [x] Finalize of the regex filter for the extracting the correct decade range\n",
    "    - Used mapping instead\n",
    "- [x] Iterate through the decades and concatenate all the resulting dataframes \n",
    "- [ ] Optionally drop rows without years in the text \n",
    "    * Only retaining text with year in order to extract years of note in the decade\n",
    "    * For mvp we can proceed as is then implement this on phase 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "surrounded-sheet",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.8 (DS)",
   "language": "python",
   "name": "ds"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
